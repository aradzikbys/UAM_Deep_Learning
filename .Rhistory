par(mfcol = c(3, 3)) # Split the screen
par(mar = c(0, 0, 3, 0), xaxs = 'i', yaxs = 'i') # Margins
for (i in 1:9) {
# x train has 3 dimensions, i-image and all columns and rows
im <- x_train[i,,]
# reverse colors
im <- t(apply(im, 2, rev))
#image in greyscale
image(1:28, 1:28, im, col = gray((255:0) / 255),
xaxt = 'n', main = paste(y_train[i]))
}
par(mfcol = c(3, 3)) # Split the screen
par(mar = c(0, 0, 3, 0), xaxs = 'i', yaxs = 'i') # Margins
for (i in 1:9) {
# x train has 3 dimensions, i-image and all columns and rows
im <- x_train[i,,]
# reverse colors
im <- t(apply(im, 2, rev))
#image in greyscale
image(1:28, 1:28, im, col = gray((255:0) / 255),
xaxt = 'n', main = paste(y_train[i]))
}
mnist <- dataset_mnist()
# %<-% operator will split mnist$train into  2 elements: x_train, y_train
c(x_train, y_train) %<-% mnist$train # Train set features, train set labels
# same for test (so we will not have lists, but matrix)
c(x_test, y_test) %<-% mnist$test # Test set features, test set labels
par(mfcol = c(3, 3)) # Split the screen
par(mar = c(0, 0, 3, 0), xaxs = 'i', yaxs = 'i') # Margins
for (i in 1:9) {
# x train has 3 dimensions, i-image and all columns and rows
im <- x_train[i,,]
# reverse colors
im <- t(apply(im, 2, rev))
#image in greyscale
image(1:28, 1:28, im, col = gray((255:0) / 255),
xaxt = 'n', main = paste(y_train[i]))
}
par(mfcol = c(3, 3)) # Split the screen
par(mar = c(0, 0, 3, 0), xaxs = 'i', yaxs = 'i') # Margins
for (i in 1:9) {
# x train has 3 dimensions, i-image and all columns and rows
im <- x_train[i,,]
# reverse colors
im <- t(apply(im, 2, rev))
#image in greyscale
image(1:28, 1:28, im, col = gray((255:0) / 255),
xaxt = 'n', main = paste(y_train[i]))
}
par(mfcol = c(3, 3)) # Split the screen
par(mar = c(0, 0, 3, 0), xaxs = 'i', yaxs = 'i') # Margins
for (i in 1:9) {
# x train has 3 dimensions, i-image and all columns and rows
im <- x_train[i,,]
# reverse colors
im <- t(apply(im, 2, rev))
#image in greyscale
image(1:28, 1:28, im, col = gray((255:0) / 255),
xaxt = 'n', main = paste(y_train[i]))
}
# Reshape
x_train <- array_reshape(x_train, c(nrow(x_train), 28 * 28))
x_test <- array_reshape(x_test, c(nrow(x_test), 28 * 28))
# Rescale
x_train <- x_train / 255
x_test <- x_test / 255
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)
head(y_train, 9)
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = 'relu', input_shape = 28 * 28) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 10, activation = 'softmax')
summary(model)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_adam(),
metrics = 'accuracy')
model %>% fit(x_train,
y_train,
epochs = 50, # Number of epochs
batch_size = 128, # Size of batch in single step
validation_split = 0.2 # Percent of data in validation sets
) -> model_dnn
plot(model_dnn)
model %>% evaluate(x_train, y_train) # Evaluate the model’s performance on the train data
model %>% evaluate(x_test, y_test) # Evaluate the model’s performance on the test data
model %>% predict(x_test) -> predictions # Predicted probabilities on test data
model %>% predict_classes(x_test) -> predicted_digits # Predicted digits on test data
model %>% predict(x_test) %>% k_argmax()-> predictions # Predicted probabilities on test data
model %>% predict_classes(x_test) %>% k_argmax()-> predicted_digits # Predicted digits on test data
model %>% predict(x_test) -> predictions # Predicted probabilities on test data
model %>% predict(x_test) %>% k_argmax() -> predicted_digits # Predicted digits on test data
par(mfcol = c(5, 5))
par(mar = c(0, 0, 1.5, 0), xaxs = 'i', yaxs = 'i')
for (i in 1:25) {
img <- mnist$test$x[i, , ]
img <- t(apply(img, 2, rev))
if (predicted_digits[i] == mnist$test$y[i]) {
color <- '#008800'
} else {
color <- '#bb0000'
}
image(1:28, 1:28, img, col = gray((255:0) / 255), xaxt = 'n', yaxt = 'n',
main = paste0(predicted_digits[i], ' (',
mnist$test$y[i], ')'),
col.main = color)
}
model %>% predict(x_test) %>% k_argmax() %>% as.numeric() -> predicted_digits # Predicted digits on test data
model %>% predict(x_test) -> predictions # Predicted probabilities on test data
model %>% predict(x_test) %>% k_argmax() %>% as.numeric() -> predicted_digits # Predicted digits on test data
par(mfcol = c(5, 5))
par(mar = c(0, 0, 1.5, 0), xaxs = 'i', yaxs = 'i')
for (i in 1:25) {
img <- mnist$test$x[i, , ]
img <- t(apply(img, 2, rev))
if (predicted_digits[i] == mnist$test$y[i]) {
color <- '#008800'
} else {
color <- '#bb0000'
}
image(1:28, 1:28, img, col = gray((255:0) / 255), xaxt = 'n', yaxt = 'n',
main = paste0(predicted_digits[i], ' (',
mnist$test$y[i], ')'),
col.main = color)
}
data.frame(table(predicted_digits, mnist$test$y)) %>%
setNames(c('Prediction', 'Reference', 'Freq')) %>%
mutate(GoodBad = ifelse(Prediction == Reference, 'Correct', 'Incorrect')) -> conf_table
conf_table %>%
ggplot(aes(y = Reference, x = Prediction, fill = GoodBad, alpha = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = 0.5, fontface  = 'bold', alpha = 1) +
scale_fill_manual(values = c(Correct = 'green', Incorrect = 'red')) +
guides(alpha = FALSE) +
theme_bw() +
ylim(rev(levels(conf_table$Reference)))
data.frame(table(predicted_digits, mnist$test$y)) %>%
setNames(c('Prediction', 'Reference', 'Freq')) %>%
mutate(GoodBad = ifelse(Prediction == Reference, 'Correct', 'Incorrect')) -> conf_table
conf_table %>%
ggplot(aes(y = Reference, x = Prediction, fill = GoodBad, alpha = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = 0.5, fontface  = 'bold', alpha = 1) +
scale_fill_manual(values = c(Correct = 'green', Incorrect = 'red')) +
guides(alpha = none) +
theme_bw() +
ylim(rev(levels(conf_table$Reference)))
data.frame(table(predicted_digits, mnist$test$y)) %>%
setNames(c('Prediction', 'Reference', 'Freq')) %>%
mutate(GoodBad = ifelse(Prediction == Reference, 'Correct', 'Incorrect')) -> conf_table
conf_table %>%
ggplot(aes(y = Reference, x = Prediction, fill = GoodBad, alpha = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = 0.5, fontface  = 'bold', alpha = 1) +
scale_fill_manual(values = c(Correct = 'green', Incorrect = 'red')) +
guides(alpha = 'none') +
theme_bw() +
ylim(rev(levels(conf_table$Reference)))
library(h2o)
library(ggplot2)
library(dplyr)
library(wesanderson)
mushrooms <- read.csv('https://tinyurl.com/hmkhs9au')
mushrooms <- mushrooms %>%
# Remove not needed characters
mutate(across(1:23, ~ substr(.x, 3,3))) %>%
# Change columns to factor (initially set as strings)
mutate(across(everything(), as.factor))
ggplot(mushrooms, aes(odor)) +
geom_bar(position="dodge", aes(fill = class)) +
scale_fill_manual(name = 'Edible/Poisonous', values = wes_palette('Moonrise2', type = 'discrete')) +
labs(x = 'Odor', y = 'Count')+
scale_x_discrete(labels=c('a (almond)', 'c (creosote)', 'f (foul)', 'l (anise)', 'm ( musty)',
'n (none)', 'p (pungent)', 's (spicy)', 'y (fishy)'))
h2o.init(nthreads = -1,
max_mem_size = '4G')
mushrooms_hex <- as.h2o(mushrooms, destination_frame = 'mushrooms_hex')
# Split data set to train & test
mushrooms_split <- h2o.splitFrame(data = mushrooms_hex, ratios = 0.75)
mushrooms_train <- mushrooms_split[[1]]
mushrooms_test <- mushrooms_split[[2]]
h2o.shutdown(prompt = TRUE)
library(h2o)
library(ggplot2)
library(dplyr)
library(wesanderson)
h2o.init(nthreads = -1,
max_mem_size = '4G')
mushrooms <- read.csv('https://tinyurl.com/hmkhs9au')
# Adapt data set for further analysis
mushrooms <- mushrooms %>%
# Remove not needed characters
mutate(across(1:23, ~ substr(.x, 3,3))) %>%
# Change columns to factor (initially set as strings)
mutate(across(everything(), as.factor))
skimr::skim(mushrooms)
mushrooms_hex <- as.h2o(mushrooms, destination_frame = 'mushrooms_hex')
# Split data set to train & test
mushrooms_split <- h2o.splitFrame(data = mushrooms_hex, ratios = 0.75)
h2o.shutdown(prompt = TRUE)
library(h2o)
library(ggplot2)
library(dplyr)
library(wesanderson)
h2o.init(nthreads = -1,
max_mem_size = '4G')
mushrooms <- read.csv('https://tinyurl.com/hmkhs9au')
# Adapt data set for further analysis
mushrooms <- mushrooms %>%
# Remove not needed characters
mutate(across(1:23, ~ substr(.x, 3,3))) %>%
# Change columns to factor (initially set as strings)
mutate(across(everything(), as.factor))
mushrooms_hex <- as.h2o(mushrooms, destination_frame = 'mushrooms_hex')
# Split data set to train & test
mushrooms_split <- h2o.splitFrame(data = mushrooms_hex, ratios = 0.75)
mushrooms_train <- mushrooms_split[[1]]
mushrooms_test <- mushrooms_split[[2]]
mushrooms_model <- h2o.deeplearning(
y = 23,
x = 1:22,
training_frame = mushrooms_train,
validation_frame = mushrooms_test,
distribution = 'multinomial',
activation = 'RectifierWithDropout',
hidden = c(300, 300, 300),
input_dropout_ratio = 0.2,
l1 = 1e-5,
epochs = 60,
variable_importances = TRUE)
mushrooms_model <- h2o.deeplearning(
y = 23,
x = 1:22,
training_frame = mushrooms_train,
validation_frame = mushrooms_test,
distribution = 'multinomial',
activation = 'RectifierWithDropout',
hidden = c(300, 300, 300),
input_dropout_ratio = 0.2,
l1 = 1e-5,
epochs = 40,
variable_importances = TRUE)
(exm <- h2o.explain(mushrooms_model, mushrooms_test))
# Model evaluation
expl_mushroom <- h2o.explain(mushrooms_model, mushrooms_test)
expl_mushroom
print(expl_mushroom)
# Odor vs class
ggplot(mushrooms, aes(odor)) +
geom_bar(position="dodge", aes(fill = class)) +
scale_fill_manual(name = 'Edible/Poisonous', values = wes_palette('Moonrise2', type = 'discrete')) +
labs(x = 'Odor', y = 'Count')+
scale_x_discrete(labels=c('almond', 'creosote', 'foul', 'anise', 'musty', 'none',
'pungent', 'spicy', 'fishy')
))
# Odor vs class
ggplot(mushrooms, aes(odor)) +
geom_bar(position="dodge", aes(fill = class)) +
scale_fill_manual(name = 'Edible/Poisonous', values = wes_palette('Moonrise2', type = 'discrete')) +
labs(x = 'Odor', y = 'Count')+
scale_x_discrete(labels=c('almond', 'creosote', 'foul', 'anise', 'musty', 'none',
'pungent', 'spicy', 'fishy'))
# Load libraries
library(h2o)
library(ggplot2)
library(dplyr)
library(wesanderson)
# Disable progress bar in document
h2o.no_progress()
# Start h2o cluster
h2o.init(nthreads = -1,
max_mem_size = '4G')
# Load file
mushrooms <- read.csv('https://tinyurl.com/hmkhs9au')
# Transform data set for further analysis
mushrooms <- mushrooms %>%
# Remove not needed characters
mutate(across(1:23, ~ substr(.x, 3,3))) %>%
# Change columns from strings to factors
mutate(across(everything(), as.factor))
# Load data to h2o cluster
mushrooms_hex <- as.h2o(mushrooms, destination_frame = 'mushrooms_hex')
# Split data set to train (75%) & test (25%)
mushrooms_split <- h2o.splitFrame(data = mushrooms_hex, ratios = 0.75)
mushrooms_train <- mushrooms_split[[1]]
mushrooms_test <- mushrooms_split[[2]]
# Build and train Deep Learning model
mushrooms_dl <- h2o.deeplearning(
y = 23,
x = 1:22,
training_frame = mushrooms_train,
validation_frame = mushrooms_test,
distribution = 'multinomial',
activation = 'RectifierWithDropout',
hidden = c(300, 300, 300),
input_dropout_ratio = 0.2,
l1 = 1e-5,
epochs = 30,
variable_importances = TRUE,
# Set seed for reproducible results:
seed = 123)
# Learning curve plot
h2o.learning_curve_plot(mushrooms_dl)
# Confusion matrix
h2o.confusionMatrix(mushrooms_dl, mushrooms_test, valid = FALSE, xval = FALSE)
# Build and train Deep Learning model
mushrooms_dl <- h2o.deeplearning(
y = 23,
x = 1:22,
training_frame = mushrooms_train,
validation_frame = mushrooms_test,
distribution = 'multinomial',
activation = 'RectifierWithDropout',
hidden = c(300, 300, 300),
input_dropout_ratio = 0.2,
l1 = 1e-5,
epochs = 45,
variable_importances = TRUE,
# Set seed for reproducible results:
seed = 123)
# Learning curve plot
h2o.learning_curve_plot(mushrooms_dl)
# Confusion matrix
h2o.confusionMatrix(mushrooms_dl, mushrooms_test, valid = FALSE, xval = FALSE)
# If needed, predictions can be done on test data set
# (which was used for validation in model training)
mushroom_pred <- h2o.predict(object = mushrooms_dl,
newdata = mushrooms_test)
# Confusion matrix as simple table: test vs predictions
table(as.data.frame(mushrooms_test[,23])[,1],
as.data.frame(mushroom_pred[,1])[,1])
# Importance of parameters
h2o.varimp_plot(mushrooms_dl)
# Build and train Deep Learning model
mushrooms_dl <- h2o.deeplearning(
y = 23,
x = 1:22,
training_frame = mushrooms_train,
validation_frame = mushrooms_test,
distribution = 'multinomial',
activation = 'RectifierWithDropout',
hidden = c(100, 100, 100),
input_dropout_ratio = 0.2,
l1 = 1e-5,
epochs = 45,
variable_importances = TRUE,
# Set seed for reproducible results:
seed = 123)
# Learning curve plot
h2o.learning_curve_plot(mushrooms_dl)
# Build and train Deep Learning model
mushrooms_dl <- h2o.deeplearning(
y = 23,
x = 1:22,
training_frame = mushrooms_train,
validation_frame = mushrooms_test,
distribution = 'multinomial',
activation = 'RectifierWithDropout',
hidden = c(100, 100, 100),
input_dropout_ratio = 0.2,
l1 = 1e-5,
epochs = 55,
variable_importances = TRUE,
# Set seed for reproducible results:
seed = 123)
# Learning curve plot
h2o.learning_curve_plot(mushrooms_dl)
# Build and train Deep Learning model
mushrooms_dl <- h2o.deeplearning(
y = 23,
x = 1:22,
training_frame = mushrooms_train,
validation_frame = mushrooms_test,
distribution = 'multinomial',
activation = 'RectifierWithDropout',
hidden = c(200, 200, 200),
input_dropout_ratio = 0.2,
l1 = 1e-5,
epochs = 55,
variable_importances = TRUE,
# Set seed for reproducible results:
seed = 123)
# Learning curve plot
h2o.learning_curve_plot(mushrooms_dl)
# Build and train Deep Learning model
mushrooms_dl <- h2o.deeplearning(
y = 23,
x = 1:22,
training_frame = mushrooms_train,
validation_frame = mushrooms_test,
distribution = 'multinomial',
activation = 'RectifierWithDropout',
hidden = c(100, 200, 100),
input_dropout_ratio = 0.2,
l1 = 1e-5,
epochs = 55,
variable_importances = TRUE,
# Set seed for reproducible results:
seed = 123)
# Learning curve plot
h2o.learning_curve_plot(mushrooms_dl)
# Confusion matrix
h2o.confusionMatrix(mushrooms_dl, mushrooms_test, valid = FALSE, xval = FALSE)
# If needed, predictions can be done on test data set
# (which was used for validation in model training)
mushroom_pred <- h2o.predict(object = mushrooms_dl,
newdata = mushrooms_test)
# Confusion matrix as simple table: test vs predictions
table(as.data.frame(mushrooms_test[,23])[,1],
as.data.frame(mushroom_pred[,1])[,1])
# Importance of parameters
h2o.varimp_plot(mushrooms_dl)
# Importance of parameters
h2o.varimp_plot(mushrooms_dl)
# Importance of parameters
h2o.varimp_plot(mushrooms_dl)
# Importance of parameters
h2o.varimp_plot(mushrooms_dl)
ggplot(mushrooms, aes(odor)) +
geom_bar(position="dodge", aes(fill = class)) +
scale_fill_manual(name = 'Edible/ Poisonous', values = wes_palette('Moonrise2', type = 'discrete')) +
labs(x = 'Odor', y = 'Count')+
scale_x_discrete(labels=c('almond', 'creosote', 'foul', 'anise', 'musty', 'none', 'pungent', 'spicy', 'fishy'))
mushrooms
head(mushrooms)
# Odor vs class
ggplot(mushrooms, aes(spore.print.color)) +
geom_bar(position="dodge", aes(fill = class)) +
scale_fill_manual(name = 'Edible/Poisonous', values = wes_palette('Moonrise2', type = 'discrete')) +
labs(x = 'Odor', y = 'Count')
scale_x_discrete(labels=c('buff', 'chocolate', 'black', 'brown', 'orange', 'green',
'purple', 'white', 'yellow'))
# Odor vs class
ggplot(mushrooms, aes(spore.print.color)) +
geom_bar(position="dodge", aes(fill = class)) +
scale_fill_manual(name = 'Edible/Poisonous', values = wes_palette('Moonrise2', type = 'discrete')) +
labs(x = 'Odor', y = 'Count')+
scale_x_discrete(labels=c('buff', 'chocolate', 'black', 'brown', 'orange', 'green',
'purple', 'white', 'yellow'))
mushrooms_auoml <- h2o.automl(y = 23,
x = 1:22,
training_frame = mushrooms_train,
max_runtime_secs = 30,
max_models = 20)
h2o.pd_multi_plot(mushrooms_auoml, mushrooms_test, class)
h2o.pd_multi_plot(mushrooms_auoml, mushrooms_test, mushrooms$class)
mushrooms_test
h2o.pd_multi_plot(mushrooms_auoml, mushrooms_test, "class")
h2o.pd_multi_plot(mushrooms_auoml, mushrooms_test, "odor")
# Leaderboard
h2o.get_leaderboard(object = mushrooms_auoml, extra_columns = "ALL")
ggplot(mushrooms, aes(odor)) +
geom_bar(position="dodge", aes(fill = class)) +
scale_fill_manual(name = 'Edible/ Poisonous', values = wes_palette('Moonrise2', type = 'discrete')) +
labs(x = 'Odor', y = 'Count')+
scale_x_discrete(labels=c('almond', 'creosote', 'foul', 'anise', 'musty', 'none', 'pungent', 'spicy', 'fishy'))
ggplot(mushrooms, aes(odor)) +
geom_bar(position="dodge", aes(fill = class)) +
scale_fill_manual(name = 'Edible/ Poisonous', values = wes_palette('Moonrise2', type = 'discrete')) +
labs(x = 'Odor', y = 'Count')+
scale_x_discrete(labels=c('almond', 'creosote', 'foul', 'anise', 'musty', 'none', 'pungent', 'spicy', 'fishy'))
ggplot(mushrooms, aes(spore.print.color)) +
geom_bar(position="dodge", aes(fill = class)) +
scale_fill_manual(name = 'Edible/Poisonous', values = wes_palette('Moonrise2', type = 'discrete')) +
labs(x = 'Odor', y = 'Count')+
scale_x_discrete(labels=c('buff', 'chocolate', 'black', 'brown', 'orange', 'green', 'purple', 'white', 'yellow'))
ggplot(mushrooms, aes(odor)) +
geom_bar(position="dodge", aes(fill = class)) +
scale_fill_manual(name = 'Edible/ Poisonous', values = wes_palette('Moonrise2', type = 'discrete')) +
labs(x = 'Odor', y = 'Count')+
scale_x_discrete(labels=c('almond', 'creosote', 'foul', 'anise', 'musty', 'none', 'pungent', 'spicy', 'fishy'))
ggplot(mushrooms, aes(odor)) +
geom_bar(position="dodge", aes(fill = class)) +
scale_fill_manual(name = 'Edible/ Poisonous', values = wes_palette('Moonrise2', type = 'discrete')) +
labs(x = 'Odor', y = 'Count')+
scale_x_discrete(labels=c('almond', 'creosote', 'foul', 'anise', 'musty', 'none', 'pungent', 'spicy', 'fishy'))
ggplot(mushrooms, aes(spore.print.color)) +
geom_bar(position="dodge", aes(fill = class)) +
scale_fill_manual(name = 'Edible/Poisonous', values = wes_palette('Moonrise2', type = 'discrete')) +
labs(x = 'Odor', y = 'Count')+
scale_x_discrete(labels=c('buff', 'chocolate', 'black', 'brown', 'orange', 'green', 'purple', 'white', 'yellow'))
# Importance of parameters
h2o.varimp_plot(mushrooms_dl)
# Importance of parameters
h2o.varimp_plot(mushrooms_dl)
# Learning curve plot
h2o.learning_curve_plot(mushrooms_dl)
h2o.get_leaderboard(object = mushrooms_auoml, extra_columns = "ALL")
as.data.frame(h2o.get_leaderboard(object = mushrooms_auoml, extra_columns = "ALL"))
source("C:/Users/User/OneDrive/Edu/Deep Learning/01_shrooms.R", echo=TRUE)
as.tibble(h2o.get_leaderboard(object = mushrooms_auoml, extra_columns = "ALL"))
h2o.init(nthreads = -1,
max_mem_size = '4G')
mushrooms_auoml <- h2o.automl(y = 23,
x = 1:22,
training_frame = mushrooms_train,
max_runtime_secs = 30,
max_models = 20)
h2o.shutdown(prompt = TRUE)
h2o.init(nthreads = -1,
max_mem_size = '4G')
# Split data set to train & test
mushrooms_split <- h2o.splitFrame(data = mushrooms_hex, ratios = 0.75)
mushrooms_hex <- as.h2o(mushrooms, destination_frame = 'mushrooms_hex')
mushrooms_hex
# Split data set to train & test
mushrooms_split <- h2o.splitFrame(data = mushrooms_hex, ratios = 0.75)
h2o.shutdown(prompt = TRUE)
